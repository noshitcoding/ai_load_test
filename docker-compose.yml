services:
  load-tester:
    image: nginx:alpine
    container_name: llm-load-tester
    ports:
      - "8088:80"
    volumes:
      - ./index.html:/usr/share/nginx/html/index.html:ro
      - ./nginx.conf:/etc/nginx/conf.d/default.conf:ro
      - ./data:/usr/share/nginx/html/data
    depends_on:
      ws-proxy:
        condition: service_healthy
        required: true
    healthcheck:
      test: ["CMD-SHELL", "wget -q -O /dev/null http://127.0.0.1/ || exit 1"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 10s
    restart: unless-stopped

  ws-proxy:
    build:
      context: .
      dockerfile: Dockerfile.ws-proxy
    container_name: llm-ws-proxy
    volumes:
      - ./ws_proxy.py:/app/ws_proxy.py:ro
    expose:
      - "8765"
    healthcheck:
      test: ["CMD", "python", "-c", "import socket,sys;s=socket.socket();s.settimeout(2);s.connect(('127.0.0.1',8765));s.close();sys.exit(0)"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 10s
    restart: unless-stopped

  load-balancer:
    build:
      context: .
      dockerfile: Dockerfile.load-balancer
    container_name: llm-load-balancer
    ports:
      - "8090:8090"
    volumes:
      - ./load_balancer.py:/app/load_balancer.py:ro
      - ./load_balancer_admin.html:/app/load_balancer_admin.html:ro
      - ./data:/data
    environment:
      LB_PORT: "8090"
      LB_DB_PATH: "/data/load_balancer.db"
      LB_ADMIN_TOKEN: "${LB_ADMIN_TOKEN:-}"
      LB_CLIENT_TOKENS: "${LB_CLIENT_TOKENS:-}"
      LB_FAIL_THRESHOLD: "3"
      LB_COOLDOWN_SECONDS: "20"
      LB_MAX_CONNECTIONS: "500"
      LB_MAX_KEEPALIVE: "200"
      LB_DEFAULT_TIMEOUT_SECONDS: "120"
      LB_LOG_LEVEL: "INFO"
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request,sys;resp=urllib.request.urlopen('http://127.0.0.1:8090/health',timeout=3);sys.exit(0 if resp.status==200 else 1)"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 10s
    restart: unless-stopped
